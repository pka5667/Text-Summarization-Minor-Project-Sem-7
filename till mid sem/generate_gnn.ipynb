{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import clear_output # to clear the large outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Number</th>\n",
       "      <th>Sentence Number</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 91</th>\n",
       "      <th>Feature 92</th>\n",
       "      <th>Feature 93</th>\n",
       "      <th>Feature 94</th>\n",
       "      <th>Feature 95</th>\n",
       "      <th>Feature 96</th>\n",
       "      <th>Feature 97</th>\n",
       "      <th>Feature 98</th>\n",
       "      <th>Feature 99</th>\n",
       "      <th>Feature 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.168716</td>\n",
       "      <td>-5.406358</td>\n",
       "      <td>1.326604</td>\n",
       "      <td>9.634008</td>\n",
       "      <td>-0.076849</td>\n",
       "      <td>-1.104372</td>\n",
       "      <td>-0.415806</td>\n",
       "      <td>-0.480926</td>\n",
       "      <td>...</td>\n",
       "      <td>5.358544</td>\n",
       "      <td>-1.592642</td>\n",
       "      <td>1.034011</td>\n",
       "      <td>9.535279</td>\n",
       "      <td>2.598292</td>\n",
       "      <td>5.612475</td>\n",
       "      <td>-4.350582</td>\n",
       "      <td>-0.964401</td>\n",
       "      <td>-1.292501</td>\n",
       "      <td>3.694599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333690</td>\n",
       "      <td>-1.051619</td>\n",
       "      <td>0.216564</td>\n",
       "      <td>6.122249</td>\n",
       "      <td>2.214809</td>\n",
       "      <td>-0.725307</td>\n",
       "      <td>-0.830446</td>\n",
       "      <td>3.878453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.961587</td>\n",
       "      <td>0.208162</td>\n",
       "      <td>2.276517</td>\n",
       "      <td>3.888922</td>\n",
       "      <td>4.042837</td>\n",
       "      <td>5.367699</td>\n",
       "      <td>-1.329080</td>\n",
       "      <td>-0.513146</td>\n",
       "      <td>1.002153</td>\n",
       "      <td>1.096816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.755151</td>\n",
       "      <td>-1.945825</td>\n",
       "      <td>1.523190</td>\n",
       "      <td>7.578938</td>\n",
       "      <td>0.057999</td>\n",
       "      <td>-2.244677</td>\n",
       "      <td>-0.843832</td>\n",
       "      <td>2.504396</td>\n",
       "      <td>...</td>\n",
       "      <td>4.913831</td>\n",
       "      <td>-0.246198</td>\n",
       "      <td>0.594669</td>\n",
       "      <td>6.016462</td>\n",
       "      <td>1.722590</td>\n",
       "      <td>5.567656</td>\n",
       "      <td>-3.447634</td>\n",
       "      <td>0.647401</td>\n",
       "      <td>-0.364287</td>\n",
       "      <td>2.557158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>-9.801075</td>\n",
       "      <td>-1.865499</td>\n",
       "      <td>18.202757</td>\n",
       "      <td>18.659924</td>\n",
       "      <td>-4.779880</td>\n",
       "      <td>4.589435</td>\n",
       "      <td>-12.752604</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.412796</td>\n",
       "      <td>9.317993</td>\n",
       "      <td>5.314600</td>\n",
       "      <td>20.374498</td>\n",
       "      <td>6.672820</td>\n",
       "      <td>28.156467</td>\n",
       "      <td>21.488192</td>\n",
       "      <td>-17.480896</td>\n",
       "      <td>-16.550327</td>\n",
       "      <td>8.181047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.340207</td>\n",
       "      <td>-35.000464</td>\n",
       "      <td>-3.669642</td>\n",
       "      <td>28.096300</td>\n",
       "      <td>4.814506</td>\n",
       "      <td>-28.647469</td>\n",
       "      <td>-3.292072</td>\n",
       "      <td>8.200159</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.041115</td>\n",
       "      <td>5.776569</td>\n",
       "      <td>9.864917</td>\n",
       "      <td>38.569895</td>\n",
       "      <td>17.010353</td>\n",
       "      <td>32.720708</td>\n",
       "      <td>4.465261</td>\n",
       "      <td>-31.103429</td>\n",
       "      <td>-17.649040</td>\n",
       "      <td>12.265246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   File Number  Sentence Number  Feature 1  Feature 2  Feature 3  Feature 4  \\\n",
       "0            0                0  -0.168716  -5.406358   1.326604   9.634008   \n",
       "1            0                1  -1.333690  -1.051619   0.216564   6.122249   \n",
       "2            0                2  -0.755151  -1.945825   1.523190   7.578938   \n",
       "3            0                3   0.059533  -9.801075  -1.865499  18.202757   \n",
       "4            0                4   9.340207 -35.000464  -3.669642  28.096300   \n",
       "\n",
       "   Feature 5  Feature 6  Feature 7  Feature 8  ...  Feature 91  Feature 92  \\\n",
       "0  -0.076849  -1.104372  -0.415806  -0.480926  ...    5.358544   -1.592642   \n",
       "1   2.214809  -0.725307  -0.830446   3.878453  ...   -0.961587    0.208162   \n",
       "2   0.057999  -2.244677  -0.843832   2.504396  ...    4.913831   -0.246198   \n",
       "3  18.659924  -4.779880   4.589435 -12.752604  ...  -13.412796    9.317993   \n",
       "4   4.814506 -28.647469  -3.292072   8.200159  ...  -11.041115    5.776569   \n",
       "\n",
       "   Feature 93  Feature 94  Feature 95  Feature 96  Feature 97  Feature 98  \\\n",
       "0    1.034011    9.535279    2.598292    5.612475   -4.350582   -0.964401   \n",
       "1    2.276517    3.888922    4.042837    5.367699   -1.329080   -0.513146   \n",
       "2    0.594669    6.016462    1.722590    5.567656   -3.447634    0.647401   \n",
       "3    5.314600   20.374498    6.672820   28.156467   21.488192  -17.480896   \n",
       "4    9.864917   38.569895   17.010353   32.720708    4.465261  -31.103429   \n",
       "\n",
       "   Feature 99  Feature 100  \n",
       "0   -1.292501     3.694599  \n",
       "1    1.002153     1.096816  \n",
       "2   -0.364287     2.557158  \n",
       "3  -16.550327     8.181047  \n",
       "4  -17.649040    12.265246  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./features/embeddings_using_word2vec.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph_info tuple\n",
    "It consists of the following\n",
    "- __node_features__ : This is a [num_nodes, num_features] shaped NumPy array that includes the node features. In this dataset, the nodes are the papers, and the node_features are the word-presence binary vectors of each paper.\n",
    "- __edges__: This is [num_edges, num_edges] NumPy array representing a sparse adjacency matrix of the links between the nodes. In this example, the links are the citations between the papers.\n",
    "- __edge_weights__ (optional): This is a [num_edges] NumPy array that includes the edge weights, which quantify the relationships between nodes in the graph. In this example, there are no weights for the paper citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a graph convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from spektral.layers.convolutional import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class GraphConvolutionLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(GraphConvolutionLayer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(\"weight\", (input_shape[-1], self.units), initializer=\"random_normal\")\n",
    "\n",
    "    def call(self, inputs, adjecency_matrix):\n",
    "        adjecency_matrix = tf.convert_to_tensor(adjecency_matrix, dtype=tf.float32, name=\"adjecency_matrix\")\n",
    "        adjecency_matrix = tf.linalg.diag(tf.reduce_sum(adjecency_matrix, axis=-1)) @ adjecency_matrix\n",
    "        output = tf.matmul(adjecency_matrix, tf.matmul(inputs, self.weight))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a graph neural network node classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a GNN model\n",
    "class GNNModel(Model):\n",
    "    def __init__(self, n_input_features, n_output_features):\n",
    "        super(GNNModel, self).__init__()\n",
    "        \n",
    "        # The input will have the shape [n_nodes, n_input_features]\n",
    "        self.graph_conv1 = GraphConvolutionLayer(64)\n",
    "        self.graph_conv2 = GraphConvolutionLayer(32)\n",
    "        self.dense = Dense(n_output_features, activation='softmax')  # Assume a classification problem for the node features\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # inputs is a list: [node_features, adjacency_matrix]\n",
    "        x, a = inputs\n",
    "        \n",
    "        # Pass through GNN layers\n",
    "        x = self.graph_conv1([x, a])\n",
    "        x = self.graph_conv2([x, a])\n",
    "        \n",
    "        # A dense layer for output\n",
    "        return self.dense(x)\n",
    "\n",
    "\n",
    "# Create the GNN model\n",
    "n_output_features = 2  # For instance, classifying nodes into 2 categories (include or exclude)\n",
    "model = GNNModel(n_input_features, n_output_features)\n",
    "\n",
    "# You can now compile and train the model using Keras functionalities.\n",
    "# The input to the model during training will be a list: [node_features, adjacency_matrix]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified input shape is not one of the valid types. Please specify a batch input shape of type tuple or list of input shapes. User provided input type: <class 'int'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Pulkit\\sem7\\Minor Project\\generate_gnn.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/generate_gnn.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mbuild(n_input_features)\n",
      "File \u001b[1;32mc:\\Users\\PULKIT\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:390\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    388\u001b[0m valid_types \u001b[39m=\u001b[39m (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m, tf\u001b[39m.\u001b[39mTensorShape, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(input_shape, valid_types):\n\u001b[1;32m--> 390\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSpecified input shape is not one of the valid types. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    391\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mPlease specify a batch input shape of type tuple or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    392\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mlist of input shapes. User provided \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    393\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39minput type: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(input_shape)))\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m input_shape \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs:\n\u001b[0;32m    396\u001b[0m   \u001b[39m# We create placeholders for the `None`s in the shape and build the model\u001b[39;00m\n\u001b[0;32m    397\u001b[0m   \u001b[39m# in a Graph. Since tf.Variable is compatible with both eager execution\u001b[39;00m\n\u001b[0;32m    398\u001b[0m   \u001b[39m# and graph building, the variables created after building the model in\u001b[39;00m\n\u001b[0;32m    399\u001b[0m   \u001b[39m# a Graph are still valid when executing eagerly.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "\u001b[1;31mValueError\u001b[0m: Specified input shape is not one of the valid types. Please specify a batch input shape of type tuple or list of input shapes. User provided input type: <class 'int'>."
     ]
    }
   ],
   "source": [
    "model.build(n_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Pulkit\\sem7\\Minor Project\\generate_gnn.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/generate_gnn.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49msummary()\n",
      "File \u001b[1;32mc:\\Users\\PULKIT\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2869\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[0;32m   2847\u001b[0m \u001b[39m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   2848\u001b[0m \n\u001b[0;32m   2849\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2866\u001b[0m \u001b[39m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   2867\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2868\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m-> 2869\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2870\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2871\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2872\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mthe model on a batch of data.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   2873\u001b[0m layer_utils\u001b[39m.\u001b[39mprint_summary(\n\u001b[0;32m   2874\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2875\u001b[0m     line_length\u001b[39m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2878\u001b[0m     expand_nested\u001b[39m=\u001b[39mexpand_nested,\n\u001b[0;32m   2879\u001b[0m     show_trainable\u001b[39m=\u001b[39mshow_trainable)\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the GNN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the GNN model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
