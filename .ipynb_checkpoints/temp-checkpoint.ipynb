{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjecency_matrix = np.array([[[0, 1, 0, 1],\n",
    "                              [1, 0, 1, 0],\n",
    "                              [0, 1, 0, 1],\n",
    "                              [1, 0, 1, 0]],\n",
    "                              [[0, 1, 0, 1],\n",
    "                               [1, 0, 1, 0],\n",
    "                               [0, 1, 0, 1],\n",
    "                               [1, 0, 1, 0]]], dtype=np.float32)\n",
    "adjecency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.08397953, 0.9671832 , 0.56433916, 0.02161435, 0.972338  ,\n",
       "         0.25674164, 0.90846765, 0.45541477, 0.5918641 , 0.7368677 ,\n",
       "         0.90406954, 0.42566264, 0.39023802, 0.23462583, 0.270248  ,\n",
       "         0.35411197],\n",
       "        [0.16233177, 0.8220112 , 0.42995885, 0.9182548 , 0.56719613,\n",
       "         0.19674355, 0.8754944 , 0.6025744 , 0.50079995, 0.12081806,\n",
       "         0.19654047, 0.07303093, 0.79413235, 0.9037323 , 0.9537563 ,\n",
       "         0.8532393 ],\n",
       "        [0.62491137, 0.72768843, 0.36958283, 0.4389758 , 0.07662664,\n",
       "         0.5205949 , 0.7353568 , 0.9358623 , 0.8801641 , 0.23663783,\n",
       "         0.27761418, 0.4096721 , 0.00371201, 0.02032243, 0.42524526,\n",
       "         0.791624  ],\n",
       "        [0.2173056 , 0.10939088, 0.91760945, 0.15179653, 0.8447573 ,\n",
       "         0.01354766, 0.28519994, 0.88394773, 0.6772253 , 0.86950463,\n",
       "         0.8953853 , 0.171772  , 0.8090378 , 0.41480607, 0.01047163,\n",
       "         0.4507749 ]],\n",
       "\n",
       "       [[0.09955431, 0.9118484 , 0.5882209 , 0.62056136, 0.20381086,\n",
       "         0.36399284, 0.78403276, 0.2890002 , 0.24666579, 0.15014908,\n",
       "         0.17088336, 0.5629927 , 0.8109887 , 0.9326852 , 0.22426248,\n",
       "         0.90935564],\n",
       "        [0.048629  , 0.0215573 , 0.36897454, 0.5315444 , 0.10859366,\n",
       "         0.9867619 , 0.8234277 , 0.39111784, 0.37546155, 0.5220331 ,\n",
       "         0.8039074 , 0.03606601, 0.37416914, 0.41132295, 0.46512786,\n",
       "         0.97504944],\n",
       "        [0.73159397, 0.5851621 , 0.53732085, 0.43343055, 0.83050334,\n",
       "         0.08139595, 0.1313449 , 0.40194768, 0.8032075 , 0.80464506,\n",
       "         0.51473534, 0.8375519 , 0.21125077, 0.4050007 , 0.9626726 ,\n",
       "         0.09271426],\n",
       "        [0.8425896 , 0.12292648, 0.9344718 , 0.53336334, 0.22202364,\n",
       "         0.8754567 , 0.44159997, 0.08769171, 0.08988939, 0.672919  ,\n",
       "         0.9168746 , 0.09746731, 0.56064606, 0.67772484, 0.00613621,\n",
       "         0.08324466]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = adjecency_matrix.shape[1]\n",
    "feature_dim = 16\n",
    "\n",
    "node_features = np.random.rand(2, num_nodes, feature_dim).astype(np.float32)\n",
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class GraphConvolutionLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(GraphConvolutionLayer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(\"weight\", (input_shape[-1], self.units), initializer=\"random_normal\")\n",
    "\n",
    "    def call(self, inputs, adjecency_matrix):\n",
    "        adjecency_matrix = tf.convert_to_tensor(adjecency_matrix, dtype=tf.float32, name=\"adjecency_matrix\")\n",
    "        adjecency_matrix = tf.linalg.diag(tf.reduce_sum(adjecency_matrix, axis=-1)) @ adjecency_matrix\n",
    "        print(adjecency_matrix)\n",
    "        output = tf.matmul(adjecency_matrix, tf.matmult(inputs, self.weight))\n",
    "        print(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GNNModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.gcn_layer = GraphConvolutionLayer(64)\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    \n",
    "    def call(self, inputs, adjecency_matrix):\n",
    "        x = self.gcn_layer(inputs, adjecency_matrix)\n",
    "        x = tf.keras.activations.sigmoid(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 1],\n",
       "       [1, 1, 0, 0]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some random labels for classification\n",
    "labels = np.random.randint(0, 2, size = [2, num_nodes], dtype = np.int32)\n",
    "\n",
    "labels = tf.cast(labels, dtype = tf.int32)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"graph_convolution_layer\" (type GraphConvolutionLayer).\n\nmodule 'tensorflow' has no attribute 'matmult'\n\nCall arguments received by layer \"graph_convolution_layer\" (type GraphConvolutionLayer):\n  • inputs=tf.Tensor(shape=(2, 4, 16), dtype=float32)\n  • adjecency_matrix=array([[[0., 1., 0., 1.],\n        [1., 0., 1., 0.],\n        [0., 1., 0., 1.],\n        [1., 0., 1., 0.]],\n\n       [[0., 1., 0., 1.],\n        [1., 0., 1., 0.],\n        [0., 1., 0., 1.],\n        [1., 0., 1., 0.]]], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Pulkit\\sem7\\Minor Project\\temp.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         logists \u001b[39m=\u001b[39m gnn_model(node_features, adjecency_matrix)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         logists \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(logists, (\u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mprint\u001b[39m(logists)\n",
      "File \u001b[1;32mc:\\Users\\PULKIT\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32md:\\Pulkit\\sem7\\Minor Project\\temp.ipynb Cell 7\u001b[0m in \u001b[0;36mGNNModel.call\u001b[1;34m(self, inputs, adjecency_matrix)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, adjecency_matrix):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcn_layer(inputs, adjecency_matrix)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mactivations\u001b[39m.\u001b[39msigmoid(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(x)\n",
      "\u001b[1;32md:\\Pulkit\\sem7\\Minor Project\\temp.ipynb Cell 7\u001b[0m in \u001b[0;36mGraphConvolutionLayer.call\u001b[1;34m(self, inputs, adjecency_matrix)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m adjecency_matrix \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(adjecency_matrix, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madjecency_matrix\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m adjecency_matrix \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mdiag(tf\u001b[39m.\u001b[39mreduce_sum(adjecency_matrix, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m@\u001b[39m adjecency_matrix\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmatmul(adjecency_matrix, tf\u001b[39m.\u001b[39;49mmatmult(inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Pulkit/sem7/Minor%20Project/temp.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling layer \"graph_convolution_layer\" (type GraphConvolutionLayer).\n\nmodule 'tensorflow' has no attribute 'matmult'\n\nCall arguments received by layer \"graph_convolution_layer\" (type GraphConvolutionLayer):\n  • inputs=tf.Tensor(shape=(2, 4, 16), dtype=float32)\n  • adjecency_matrix=array([[[0., 1., 0., 1.],\n        [1., 0., 1., 0.],\n        [0., 1., 0., 1.],\n        [1., 0., 1., 0.]],\n\n       [[0., 1., 0., 1.],\n        [1., 0., 1., 0.],\n        [0., 1., 0., 1.],\n        [1., 0., 1., 0.]]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# Create GNN Model\n",
    "gnn_model = GNNModel(num_classes=2)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logists = gnn_model(node_features, adjecency_matrix)\n",
    "        logists = np.reshape(logists, (2, 4))\n",
    "        print(logists)\n",
    "        loss_value = loss_fn(labels, logists)\n",
    "    grads = tape.gradient(loss_value, gnn_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, gnn_model.trainable_variables))\n",
    "    print(f'Epoch: {epoch + 1}/{num_epochs}, Loss: {loss_value.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn_model.save('model.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " graph_convolution_layer (Gr  multiple                 1024      \n",
      " aphConvolutionLayer)                                            \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,024\n",
      "Trainable params: 1,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
